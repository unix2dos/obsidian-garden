---
{"aliases":[],"tags":[],"title":"技术卡片笔记","date":"2025-06-01T07:55:23+08:00","date_modify":"2026-01-05T13:51:49+08:00","dg-publish":true,"permalink":"/Publish/技术卡片笔记/","dgPassFrontmatter":true,"created":"2025-06-01T07:55:23+08:00","updated":"2026-01-05T13:51:49+08:00"}
---


# 2026-01-05 Quanx

- vless 协议
  vless=example.com:443, method=none, password=pwd, obfs=wss, obfs-host=example.com, obfs-uri=/gnofws, tls-verification=false, fast-open=false, udp-relay=false, tag=vless-ws-tls
- quanx 的分流规则是怎么走的
	- 你访问 Netflix
	- 分流规则里应该有一条（通常是订阅自带的）：`host-keyword, netflix, 国际媒体`。
	- 流量进入 -> `国际媒体` 策略组。
	- 你在国际媒体里如果选了自动选择，它就会走测速最快的节点。
- quanx 如何实时显示速率
	- mac 是可以显示的

# 2026-01-05 Quanx 配置自己的节点和策略

在 QuanX 中，你不需要去找 "TUN 模式 " 的开关，只要运行起来，它就是 TUN 模式。

- 配置节点 (Proxies)
	- 在配置文件中找到 `[server_local]` 这一栏（如果没有可以自己写），将以下内容添加进去。这是将 VLESS 和 Trojan 翻译成 QuanX 专用 URI 格式的结果。
- 配置策略组 (Proxy Groups)
	- 在 Clash 中你有一个叫 `AWS-VPC` 的组，里面包含两个节点和 DIRECT。在 QuanX 中，我们要在 `[policy]` 栏下添加。 Clash 的 `select` 类型对应 QuanX 的 `static` 类型。
- 配置分流规则 (Rules)
	- 在配置文件中找到 `[filter_local]` 这一栏。QuanX 的规则关键字与 Clash 略有不同：
	- `DOMAIN-SUFFIX` -> `host-suffix`
	- `DOMAIN` -> `host`
	- `IP-CIDR` -> `ip-cidr`
	- `DIRECT` -> `direct`
	- 请将以下内容添加到 `[filter_local]` 的顶部（因为 QuanX 也是从上往下匹配，建议放在通用规则之前）：

# 2026-01-04 Sysprompt (系统提示词) 和 Userprompt (用户提示词)

- Sysprompt (系统提示词)：
	- 目的是 " 定调 "。它负责设定 AI 的身份（例如：" 你是一个专业的翻译家 "）、语气（例如：" 请用幽默的口吻 "）、以及边界（例如：" 不管是问什么，绝对不要回答涉及暴力的内容 "）。
	- 它的作用是持久的，贯穿整个对话过程。
- Userprompt (用户提示词)：
	- 目的是 " 执行任务 "。它通过具体的输入（例如：" 请帮我把这句话翻译成英文 "、" 帮我写一段代码 "），触发 AI 进行具体的思考和回答。
	- 它的作用通常是针对当前这一轮对话的。

 优先级与权重

- 在大多数模型架构中，Sysprompt 的优先级理论上更高，因为它代表了系统的底层规则。如果 Sysprompt 说 " 只能用中文回答 "，那么即使 Userprompt 要求 " 用英文回答 "，AI 也应该优先遵守 Sysprompt 的设定（尽管在实际操作中，有时候强烈的 Userprompt 可能会试图覆盖 Sysprompt，称为 Prompt Injection，但设计初衷是 System 优先）。

可见性

- Sysprompt：通常是开发者在后台设置的，普通用户在使用现成的 AI 产品时（如直接使用网页版聊天机器人），往往看不到这部分内容。
- Userprompt：是用户自己输入的，完全可见。

# 2026-01-03 Playwright

Playwright 可是如今 Web 自动化领域的 " 顶流明星 "。

想象一下，你有一个非常听话、手速飞快、不知疲倦的机器人替身。你告诉它：" 打开浏览器，去这个网站，输入密码，点击登录，如果有弹窗就关掉，最后把页面截图发给我。" —— Playwright 就是指挥这个机器人的 " 遥控器 "。

它是由 Microsoft（微软） 开发的，用来模拟真实用户在浏览器中操作 Web 页面（比如点击、输入、滚动、截图、拦截网络请求等）。

误区一：滥用强制等待 `time.sleep(5)`

- 现象： 为了怕页面没加载完，疯狂写代码让程序 " 睡 5 秒 "。
- 正解： 相信 Playwright 的 Auto-wait。它会自动等元素出现。如果非要等，用 `page.wait_for_selector()`，让它 " 等到出现了立刻动 "，而不是死板地等时间。

误区二：沉迷于复杂的 XPath

- 现象： 写出像 `//*[@id="app"]/div[2]/div[1]/span` 这种天书一样的定位。
- 正解： 像用户一样思考。使用 `page.get_by_text("登录")` 或者 `page.get_by_role("button", name="提交")`。这才是 Playwright 提倡的现代写法，既好读又稳。

误区三：忘记关闭 Browser Context

- 现象： 脚本跑完了，内存没释放。
- 正解： 记得使用 `browser.close()`，或者使用 Python 的 `with` 上下文管理器，让它自动打扫战场。

# 2025-12-29 白嫖谷歌相册

<https://linux.do/t/topic/198656/15>

# 2025-12-27 acme.sh Standalone

`acme.sh --issue --standalone -d dev.liuvv.com `

Standalone 模式这是重点！它不依赖你现有的 Nginx/Apache，而是自己临时占用 80 端口模拟一个网站来通过验证。

- 通常，验证域名归属权需要检查你的房子（Web 服务器）里有没有特定的东西。
- 普通模式：需要你把房子建好（安装 Nginx），门开着。
- Standalone 模式：你房子还没建好，或者不想麻烦。acme.sh 会搭一个临时的 " 假房子 "（临时微型服务器），站在门口（占用 80 端口）等检查人员来看一眼。检查完，这个临时房子就立刻拆除。

两种验证方式

- HTTP 验证（--standalone 属于这一类）
	- 快递员（CA 机构）会通过互联网直接访问 `http://dev.liuvv.com` （默认走 **80 端口**）。
- DNS 验证
	- 你告诉快递员：我不在家，或者我家大门（80 端口）被封了，但我有村口公告栏（DNS 服务器）的钥匙。我在公告栏上贴了个条子，你自己去看。
	- 快递员不访问你的服务器，而是去查全球 DNS 记录，看有没有一条特定的 TXT 记录。
	- 申请泛域名证书（如 `*.liuvv.com`）的唯一方法。

# 2025-12-25 Clash 的 Match

- MATCH：意思是 " 全匹配 " 或者 " 兜底 "。
- 作用：它必须放在规则列表的最后一行。当一个网络请求哪怕把上面所有的规则都试遍了，都没有对应上（比如不是国内 IP，也不在你的白名单里），那么它最后就会落到这一行。
- MATCH,Proxy 和 MATCH,Final 只是策略组的名字

# 2025-12-23 TUN 模式下 Baidu 会走代理吗？

```bash
- GEOIP,CN,DIRECT
- MATCH,Final
```

TUN 模式 ≠ 全局（Global）模式。

- TUN 模式决定了 " 谁会被抓进 Clash"（抓取流量的方式）。
- 规则/全局模式决定了 " 抓进来之后发往哪里 "（处理流量的策略）。
就算你开了 TUN 模式，Clash 抓到了流量后，依然会乖乖照着你的 `rules` 列表办事。如果是百度，它就放行（直连）；如果是谷歌，它就代理。

## 1. 默认模式（系统代理）—— " 靠自觉 "

在没有开启 TUN 模式时，Clash 只是在路边立了个牌子写着：" 请大家走代理通道 "。

- 浏览器 (Chrome/Safari) 很听话，看到牌子，就主动把请求交给 Clash。
- Navicat / 终端 / 很多软件是 " 老司机 "，它们根本不看这块牌子，直接不管 Clash，自顾自地开车走了。
	- 结果：这就是为什么你必须在 Navicat 里手动填代理，或者 Navicat 根本连不上。

## 2. TUN 模式（虚拟网卡）—— " 强制拦截 "

开启 TUN 模式后，Clash 在电脑里安装了一个虚拟网卡。它相当于把原来的路封了，强行修了一条隧道，所有的车（流量）必须经过这里，不管是浏览器还是 Navicat，想上网必须从这过。

- **Navicat** 以为自己在走普通的网线，其实它已经被强制拐进了 Clash 的地盘。
	- 结果：Navicat 的流量成功被 Clash 捕获了。

## 3. 接下来的步骤 —— " 查户口 "（规则 Vs 全局）

当流量（比如 Navicat 访问 AWS，或者浏览器访问百度）被 TUN 模式 " 抓 " 进 Clash 之后，Clash 会掏出你的 `Rules` 小本本开始检查：

- 如果是规则模式 (Rule)：
	- Clash 看到百度：查规则 `GEOIP,CN,DIRECT` -> 放行，直连访问（不走梯子流量）。
	- Clash 看到 AWS 内网 `10.228...`：查规则 `IP-CIDR...AWS` -> 送上梯子，走代理。
- 如果是全局模式 (Global)：
	- Clash 根本不看规则书，不管你是百度还是谷歌，统统送上梯子。

# 2025-12-23 TUN 模式和全局模式

1. Mac ClashX 的【增强模式】 = TUN 模式（它是用来 " 强行抓包 " 的机制）。
2. QuanX 的【全部代理】 = 全局模式（它是用来 " 决定去向 " 的策略）。

## Mac ClashX 的 " 增强模式 " (Enhanced Mode)

- 它是：TUN 模式 (机制)
- 它不是： 全局模式 (策略)

解释：  
ClashX 默认只会开启 " 系统代理 "，这只能接管浏览器和部分自觉的软件。  
当你打开 " 增强模式 " 时，ClashX 会利用 macOS 的特性（虚拟网卡或 Fake-IP），建立一个 " 接管一切 " 的通道。这使得 Navicat、终端、游戏等不走系统代理的软件流量都能被 ClashX 捕获。

重点： 开启 " 增强模式 " 后，你依然可以选择让 ClashX 运行在 " 规则模式 (Rule)" 下。

- 结果： Navicat 被抓进来了（因为增强模式），但访问百度依然是直连（因为规则模式）。

## Quantumult X 的 " 全部代理 " (天生就是 TUN 模式)

- 它是：全局模式 (策略)
- 它不是： TUN 模式 (机制)

解释：  
QuanX 的架构比较特殊，它在 iOS/iPadOS/Mac（M 芯片）上运行时，本质上一直都在使用 VPN/TUN 技术来接管系统流量（因为它必须创建 VPN 配置才能工作）。也就是说，QuanX 天生就是 TUN 模式，你没法关掉它的 TUN 抓包能力。

它的三个按钮控制的是 " 流量抓进来之后怎么办 "：

1. 全部直连：抓进来，全部扔给本地网络（谁都不走代理）。
2. 分流 (Rule)：抓进来，按规则办事（百度直连，谷歌代理）。
3. 全部代理 (All Proxy)：抓进来，不管是谁，全部强制走代理。

重点： 如果你选了 " 全部代理 "，访问百度也会走代理节点，可能导致百度把你当成海外用户，或者速度变慢。

# 2025-12-23 Clashx 真正的全局代理

- 点击 macOS 顶部菜单栏的 小猫图标 (ClashX 图标)。
- 找到 出站模式 (Outbound Mode) 这一项（一般在第一项）。
- 在子菜单中，选择 全局连接 (Global)。

为了让你彻底搞清楚，我把你刚才问的 TUN (增强模式) 和 全局 (Global) 结合起来，列出四种状态的效果：

## 1. 系统代理 + 全局连接 (Global) —— 最容易误解的状态

- 状态：增强模式关，出站选全局。
- 效果：你的浏览器访问百度、谷歌都会走代理。但是，你的 Navicat、终端 ping 命令依然不走代理（因为没开 TUN 抓不住它们）。

## 2. 增强模式 + 规则判断 (Rule) —— 最推荐的状态

- 状态：增强模式开，出站选规则。
- 效果：Navicat 和终端会被抓进来。百度直连，AWS 走代理。这是最智能的。

## 3. 增强模式 + 全局连接 (Global) —— 真正的 " 全电脑接管 "

- 状态：增强模式开，出站选全局。
- 效果：
	- Navicat、终端、游戏全部被抓进来。
	- 进来后，不管你是百度还是 AWS，全部强制走代理。
	- *这是当你排查问题，想强制测试某个 IP 是否通畅时使用的核武器。*

## 4. 直接连接 (Direct)

- 状态：出站模式选 " 直接连接 "。
- 效果：ClashX 变成了摆设，所有流量全部直连，相当于没开梯子。

# 2025-12-22 Aws 的 Mongodb

## Aws Market

- aws market
- MongoDB Atlas (pay-as-you-go) 不是 MongoDB Atlas Enterprise
- View purchase options
- 点击 Subscribe

You successfully purchased MongoDB Atlas Enterprise

You have successfully linked your MongoDB organization, wei's Org - 2025-12-22, to your AWS Account.

## Mongo Atlas

- Create a cluster，Dedicated 模式
- 不需要开启 Enable Global Writes (M30 and up)
- 选择 M10 ， 2GB RAM (内存) 和 2 vCPU (突发性能)。
- 关闭 Enable Business Intelligence Connector

# 2025-12-21 梯子脚本

<https://whatshub.top/>

# 2025-12-18 私有 Ip 可以访问，公网 Ip 访问不到

为什么私有 ip 可以访问，公网 ip 访问不到，我的 ip 是 192.168.1.104

- <http://10.228.1.232:6867>
- <http://30.100.100.100:6867>

安全组放行策略

- 10.0.0.0/8
- 172.16.0.0/12
- 192.168.0.0/16

原因

- 为什么公网不通？
	- 因为你访问公网 IP 时，你的来源 IP 变成了公网出口 IP，而你现有的规则里，并没有允许这个公网出口 IP 访问 6867 端口。
	- 你可以在百度或 Google 搜索 "what is my ip"，看到的那个 IP 才是 AWS 公网接口眼里看到的你的 IP。
- 为什么内网能通？
	- 这并不是因为你的本机 IP 192.168.1.104 被 AWS 信任了，而是因为你用了一个 " 中间人 "（跳板机/代理服务器）。
	- 打包出发： 路由器不会直接向互联网通过公网寻找 10.228.1.232（公网上没有这个地址），而是把你的请求加密封装进 Trojan 协议，发往代理服务器地址 aaaa.bbbb.xyz。
	- 服务器（这就是那个 Trojan 节点）收到了你的加密包。它解开包，看到你要访问的真实目标是 10.228.1.232:6867。
	- 这台 Jump Server 本身就在 AWS 的内网里（或者和目标机器网络互通）。
	- 它发起一个新的请求去连接 10.228.1.232:6867。
	- 重点来了： 此时，对于目标机器来说，请求的来源 IP (Source IP) 变成了 Jump Server 的内网 IP (比如 10.228.x.x 或 172.x.x.x)，而不再是你家里的宽带 IP 192.168.1.104 或公网 IP。

# 2025-12-15 Mihomo

- mihomo
	- Mihomo 是代理核心 (Core)
	- 对于你的手机/电脑来说，它是 Server（服务端/网关）： 你的设备把流量发给路由器上的 Mihomo，它负责接收和处理。
	- 对于你的机场（节点提供商）来说，它是 Client（客户端）： Mihomo 把处理后的数据伪装好，发送给远端的服务器。
	- 对于网页来说，它是 Backend（后端）： 那个网页只是一个前端显示器（UI），它通过 API 向后台运行的 Mihomo 核心发送指令。
- 配置
	- 策略组本身不连接互联网，它负责**做决定**。它决定把流量交给哪个具体的 " 节点 " 或者 " 下一级策略组 "。

# 2025-12-10 效率软件

- 视觉化思考的极致：Heptabase
	- 设计哲学： " 可视化学习 " 与 " 白板 (Whiteboard)"。Obsidian 强在连接，但弱在可视化。Heptabase 的哲学是：大脑的思考不是线性的，而是网状和空间化的。它允许你把 flomo 式的碎片笔记（它称为 Card）扔在一张无限大的白板上，然后通过拖拽、连线来整理逻辑。
- 对象化笔记的新星：Capacities
	- 设计哲学： " 对象 (Objects)" 而非 " 文件 "。它填补了 Notion 和 Obsidian 之间的空白。界面极美，侧边栏类似 flomo 的时间流。你不需要思考笔记存哪里，只需要思考 " 这是什么东西（书？人？灵感？）"，打上标签即可。
- Todo 类的优雅巅峰：Things 3
	- 它的 "Anytime（随时）" 和 "Someday（某天）" 列表区分得非常好。你可以把大脑里所有想做但现在做不了的事全扔进 Someday，确保收件箱清空（Inbox Zero），大脑瞬间轻松。
- 本地优先的 " 数字积木 "：Anytype
	- 设计哲学： " 本地优先 (Local-first)" + " 万物皆对象 "。它的 Dashboard 和 Set 的概念非常有逻辑美感，适合整理癖和结构化思维强的人。

# 2025-12-09 冒烟测试

冒烟测试 (Smoke Testing)，在软件测试中，是指在将代码更改部署到测试环境后，对最基本、最关键的功能进行的一次快速验证。它的目的不是为了发现深层次的 Bug，而是为了确认软件是否 " 可以运行 "，是否值得进行后续更深入的测试。它是测试流程的第一道 " 门禁 "。

 冒烟测试就像是修好电路板后第一次通电：先看看有没有冒烟（烧坏），再决定要不要拿万用表去测细节。就像买二手车，你第一件事是拧钥匙点火。如果发动机都打不着（冒烟测试失败），你就根本不需要去检查空调凉不凉、音响好不好了。

冒烟测试是 CI/CD 流水线中最应该被自动化的环节。冒烟运行时间过长（如超过 1 小时），失去了 " 快速反馈 " 的意义。

# 2025-12-08 Bootloader 锁

- 启动流程： 当你按下手机电源键时，屏幕还没有亮，Bootloader 是第一个醒来的程序。它会检查手机的硬件是否正常，然后去叫醒 " 主人 "（加载操作系统内核）。
- 安全检查： 在手机出厂时，厂商给这个 " 门卫 " 下了一道死命令：" 只能让持有我（厂商）签名的官方系统进入房子。" 也就是说，如果 Bootloader 检测到你想运行的系统不论是被篡改过，还是第三方的，它就会阻止手机启动。

正如上面所说，厂商锁住 BL 是为了安全和稳定。

- 防止恶意软件： 防止病毒在开机阶段就劫持手机。
- 防止手机变砖： 防止用户误操作刷入不匹配的系统导致手机坏掉。
- 保护数据： 如果手机丢了，小偷捡到后很难通过刷机来绕过密码锁（大部分情况下）。

既然这么好，为什么要解锁（Unlock Bootloader）呢？因为有些用户（通常是极客或发烧友）想要获得房子的 " 完全控制权 "。他们想对那个 " 门卫 " 说：" 别管我有证没证，只要是我允许的人（软件），你都得让他进来！"。解锁 BL，就是为了绕过厂商的安全签名验证机制。

## 解锁后有什么用？

一旦你解开了 Bootloader 锁，你就不再受厂商的限制，可以对手机做一些深度操作：

1. 获取 Root 权限： 这是最常见的理由。Root 就像是拿到了系统的 " 上帝钥匙 "，你可以修改系统深层文件。
2. 刷入第三方系统（Custom ROM）： 比如你的手机厂商不再提供更新了，或者你不喜欢官方系统广告太多，你可以刷入像 LineageOS、Pixel Experience 这样干净、流畅的第三方系统。
3. 删除系统自带应用： 强行卸载那些厂商预装且无法正常卸载的 " 全家桶 " 软件。
4. 安装定制内核： 为了极致的省电，或者极致的游戏性能，修改 CPU 调度。
5. 救砖： 在某些特定情况下，解锁 BL 是通过底层命令修复手机系统的必要条件。

在现代主流的安卓手机（Android 6.0 以后，尤其是近几年的新机型）上，不解锁，root 几乎是不可能的。

# 2025-12-03 证书自动续期

<https://github.com/certimate-go/certimate>

# 2025-12-02 访问 <https://liuvv.com/> 为什么不去 <https://www.liuvv.com>

- 之前 CNAME 配置如下
	- liuvv.com: <www.liuvv.com.cdn.dnsv1.com>
	- www <www.liuvv.com.cdn.dnsv1.com>

```bash
curl https://liuvv.com/
# curl: (60) SSL: no alternative certificate subject name matches target hostname 'liuvv.com'

curl https://www.liuvv.com/
# 正常
```

- 证书如下

```bash
https://blog-1300740185.cos-website.ap-beijing.myqcloud.com/
*.cos-website.ap-beijing.myqcloud.com
GlobalSign RSA OV SSL CA 2018
颁发日期    2025年3月11日星期二 17:02:43
截止日期    2026年4月12日星期日 17:02:42


https://liuvv.com/
*.cdn.myqcloud.com
TrustAsia RSA DV TLS CA G3
颁发日期    2025年6月12日星期四 08:00:00
截止日期    2026年6月13日星期六 07:59:59



https://www.liuvv.com/
liuvv.com
TrustAsia DV TLS RSA CA 2025
颁发日期    2025年9月5日星期五 08:00:00
截止日期    2025年12月4日星期四 07:59:59



# 此域名是加速域名CNAME到CDN节点上的地址，直接访问此域名则无法获取正确资源信息。
www.liuvv.com.cdn.dnsv1.com
*.cdn.myqcloud.com
TrustAsia RSA DV TLS CA G3
颁发日期    2025年6月12日星期四 08:00:00
截止日期    2026年6月13日星期六 07:59:59

```

## 原因

- 主要原因是 DNS 记录只负责 " 指路 "，不负责 " 重写地址 "。
- Cloudflare 的代理（CDN）功能未开启： 在截图的 " 代理状态 " 一栏，显示的是灰色云朵（仅 DNS）。
	- 这意味着 Cloudflare 仅仅作为一个电话本（DNS），把用户指引到你的目标服务器。
	- 用户的流量不经过 Cloudflare 的中转服务器。
	- 因此，如果你在 Cloudflare 后台设置了只有代理模式下才生效的 " 页面规则（Page Rules）" 或 " 重定向规则 "，它们现在是无法生效的。

## 如何解决

- Cloudflare " 拦截 " 对 liuvv.com 的访问
	- 类型改为 A。内容 (IPv4 地址)：改为 192.0.2.1。这是一个保留 IP，实际上不会真的去访问它。
	- 代理状态：点击那个灰色的云朵，让它变成橙色（已代理），只有橙色，后面的规则才会生效。
	- 输入：`ping liuvv.com`，显示的 IP 看起来像 `172.67.x.x` 或 `104.21.x.x`（Cloudflare 的 IP 段），说明 DNS 生效了。
- Cloudflare 的重定向功能
	- 在你的 DNS 列表里，点击 `liuvv.com` (即第一行) 右侧的编辑，将其 " 代理状态 " 从 " 仅 DNS" 改为 " 已代理 "（点击那个灰色的云朵，让它变成橙色）。
	- 开启橙色云朵后，去 Cloudflare 左侧菜单找到  Rules ->  Page Rules。
	- URL 匹配 `liuvv.com/*`，设置为 `Forwarding URL (301)`，目标填 `https://www.liuvv.com/$1`。
- 测试成功
	- `curl -L -k https://liuvv.com/`

# 2025-11-27 抓包工具 Vs 代理抓包

作为计算机学生，你可能经常听到 Wireshark 和 Fiddler/Charles，虽然都叫 " 抓包 "，但原理完全不同。

| 维度        | Wireshark / Tcpdump  | Fiddler / Charles / Burp Suite |
| --------- | -------------------- | ------------------------------ |
| **类型**    | **网卡级嗅探器 (Sniffer)** | **HTTP/HTTPS 代理服务器 (Proxy)**   |
| **工作层级**  | OSI 模型 2-7 层 (全能)    | 主要是应用层 (Layer 7)               |
| **原理**    | 旁路监听，此时它像个摄影师        | 中间人攻击 (MitM)，此时它像个传话筒          |
| **能否改包**  | 很难实时修改，主要用于**观察**    | 专长，可以拦截请求，**修改**后再发出去          |
| **HTTPS** | 极难解密 (除非有私钥或某些技巧)    | 容易解密 (通过安装伪造的 CA 证书)           |
| **适用场景**  | 网络协议分析、TCP 握手、底层排查   | Web 开发调试、接口测试、爬虫分析             |

# 2025-11-24 复式记账

复式记账（Double-Entry Bookkeeping）是一种 " 有来必有去，来去必相等 " 的记账方法。

- 单式记账（流水账）：
	- 关注点：现金的增减。
	- 记录方式：今天买午饭花了 30 元。记作：`-30元`。
	- 缺点：你只知道钱少了，但不知道这笔钱变成了什么，或者是不是欠别人的。
- 复式记账：
	- 关注点：资金的来源和去向。每一笔交易都会同时影响两个账户。
	- 核心公式：资产 = 负债 + 净资产（所有者权益）
	- 记录方式：还是买午饭花了 30 元。
		- 账户 A（钱包/资产）：减少 30 元。
		- 账户 B（餐饮支出）：增加 30 元。
	- 进阶例子（买房）：假设你首付 100 万，贷款 200 万，买了一套 300 万的房。
		- 单式记账会显得如果你花了 100 万，你就变穷了。
		- 复式记账会显示：你的现金少了 100 万，但你多了一笔 200 万的负债，同时多了一个 300 万的固定资产。你的总资产其实是增加了。

```bash
资产（Total Assets） = 负债（Liabilities） + 净资产（Equity）
```

- 买房前：
	- 左边（资产）： 100 万（现金）
	- 右边（来源）： 0（负债） + 100 万（你的净资产）
	- 此时：总资产是 100 万。
- 买房后（首付 100 万，贷款 200 万，买了 300 万的房）：
	- 左边（资产）： 0（现金花光了） + 300 万（房子） = 300 万
	- 右边（来源）： 200 万（欠银行的） + 100 万（你原本的净资产） = 300 万

你的 " 净资产 " 其实没变（暂时）： 依然是 100 万。这符合你觉得 " 应该是不变的 " 那个直觉。

# 2025-10-28 Linux DD 命令

`dd` 命令是 Linux 和其他类 Unix 系统中的一个核心工具，它的主要作用是在非常低的级别上复制和转换数据。你可以把它想象成数据世界的 " 瑞士军刀 "，能够以 " 块 "（block）为单位，对任何东西进行原始、精确的读写操作。

`dd` 的强大之处在于它的源和目的地可以是任何东西：硬盘、分区、一个普通文件，甚至是代表 " 无 " 或 " 随机数据 " 的特殊设备文件。

- `dd if=<输入源> of=<输出目标> [选项]`
	- `if=...` (Input File): 指定输入源，也就是你想要从哪里读取数据。
	- `of=...` (Output File): 指定输出目标，也就是你想要把数据写到哪里。
	- `[选项]`: 用来控制 `dd` 的行为，比如一次复制多大的数据块、复制多少次等。
- 场景

```bash
# 备份整个硬盘 `sda` 到 `sdb`：
# 警告：此操作会完全覆盖 /dev/sdb 上的所有数据！
sudo dd if=/dev/sda of=/dev/sdb bs=4M status=progress


# 将一个 ISO 镜像文件写入 U 盘：
# 假设你的U盘设备是 /dev/sdc
# 警告：这会擦除U盘上的所有数据！
sudo dd if=/path/to/ubuntu-24.04.iso of=/dev/sdc bs=4M status=progress


# 用全零覆盖硬盘（速度快，一般情况下足够安全）：
sudo dd if=/dev/zero of=/dev/sdx bs=4M status=progress

# 创建一个 1GB 大小的文件
dd if=/dev/zero of=large_file.dat bs=1G count=1
```

它不会问你 " 你确定吗？"：命令一旦敲下回车，就会立即执行，没有撤销的机会。

if 和 of 写反了就完了：如果你本想把 /dev/sda（系统盘）备份到 /dev/sdb（移动硬盘），却写成了 of=/dev/sda，那么你的系统盘就会被移动硬盘的数据（甚至是空白）覆盖，导致系统瞬间崩溃，数据全部丢失。

- 为什么不用 cp 命令呢
	- cp 和 dd 工作在完全不同的层面。cp 是文件层面的工具，而 dd 是块设备层面的底层工具。·
- 克隆整个硬盘
	- 用 `dd`：`sudo dd if=/dev/sda of=/dev/sdb`  	`dd` 会把 `/dev/sda` 的第一个字节到最后一个字节，包括主引导记录 (MBR)、分区表、所有分区、以及分区里的所有数据，完美地复制到 `/dev/sdb`。`/dev/sdb` 会成为 `/dev/sda` 的一个完美克隆体。
	- 用 `cp`：你根本做不到这件事。`cp` 无法读取 MBR 或分区表，因为它不理解 " 硬盘 " 这个物理概念，它只理解 " 文件 " 和 " 目录 "。你最多只能把一个分区挂载后，用 `cp -a` 把里面的所有文件复制到另一个挂载好的分区里，但这只是文件级别的复制，丢失了引导信息和分区表结构。

# 2025-10-27 容器标签 Latest 的绑定

1. 它不是一个智能指针：`latest` 标签不会自动指向你最新构建（build）或推送（push）的镜像。Docker 本身没有 " 最新 " 这个动态概念。
2. 它只是一个普通的标签名：`latest` 和你使用的 `20251027`、或者 `v1.0`、`my-cool-version` 一样，都只是一个普通的标签名而已。
3. 它的 " 特殊 " 在于约定俗成：
	- 默认行为：当你不指定任何 tag 进行 `docker build`、`docker pull` 或 `docker run` 时，Docker 会默认帮你加上 `:latest`。比如 `docker pull my-image` 实际上执行的是 `docker pull my-image:latest`。
	- 社区习惯：大家习惯性地会给一个项目的最新稳定版打上 `latest` 标签，方便别人快速上手。

所以，`latest` 标签指向哪个镜像，完全取决于你上一次给哪个镜像打了 `latest` 标签。它就是一个需要你手动去维护的指针。

- 在生产环境中，避免使用 `latest`：`latest` 标签是可变的，今天它可能是 A 版本，明天你更新后就变成了 B 版本。这会导致部署的不可预测性。想象一下，Kubernetes 集群中的一个节点重启了，如果它拉取的是 `:latest`，可能会拉下来一个你意想不到的新版本，导致服务不稳定甚至崩溃。
- 使用不可变标签：像你使用的日期 `20251027` 就是一个很好的实践！其他常见的还有：
	- 语义化版本：`v1.2.3`
	- Git 提交哈希：`g-a1b2c3d`  
		这些标签一旦被打上，就永远指向那一个特定的镜像版本，非常稳定和可靠。

# 2025-10-27 Docker 容器外更新代码

```bash
docker rm -f dev-ifonly-server
docker run -d --restart always --name dev-ifonly-server -p 8899:8888 -p 8890:8890 \
  -v /root/scripts/jenkins/jenkins_home/workspace/"$JOB_NAME":/app:ro \
  -v /home/ubuntu/.gitconfig:/root/.gitconfig:ro \
  -v /home/ubuntu/.git-credentials:/root/.git-credentials:ro \
  -v go-pkg-mod:/go/pkg/mod \
  -v go-build-cache:/root/.cache/go-build \
  --log-driver=fluentd --log-opt fluentd-address=log-collector-internal.ifonlyapp.com:9997 \
  -w /app -e GOPRIVATE='git.hoxigames.xyz' -e TZ='Asia/Shanghai' golang:1.21 go run . -f /app/etc/dev/config.yaml
```

最好借助 docker-compose

```bash
# 使用一个较新的、稳定的版本
version: '3.8'

services:
  # 这是你的服务名，可以自定义
  ifonly-server:
    # 容器名，对应 --name dev-ifonly-server
    container_name: dev-ifonly-server
    # 镜像，对应 golang:1.21
    image: golang:1.21
    # 重启策略，对应 --restart always
    restart: always
    # 端口映射，对应 -p
    ports:
      - "8899:8888"
      - "8890:8890"
    # 卷挂载，对应 -v
    volumes:
      # 注意：${JOB_NAME} 会读取你运行 docker-compose 命令时环境中的变量
      - /root/scripts/jenkins/jenkins_home/workspace/${JOB_NAME}:/app:ro
      - /home/ubuntu/.gitconfig:/root/.gitconfig:ro
      - /home/ubuntu/.git-credentials:/root/.git-credentials:ro
      # 这是具名卷 (Named Volumes)，更方便管理
      - go-pkg-mod:/go/pkg/mod
      - go-build-cache:/root/.cache/go-build
    # 工作目录，对应 -w /app
    working_dir: /app
    # 环境变量，对应 -e
    environment:
      - GOPRIVATE=git.hoxigames.xyz
      - TZ=Asia/Shanghai
    # 日志驱动，对应 --log-driver 和 --log-opt
    logging:
      driver: fluentd
      options:
        fluentd-address: "log-collector-internal.ifonlyapp.com:9997"
    # 容器启动后执行的命令，对应 go run . ...
    command: ["go", "run", ".", "-f", "/app/etc/dev/config.yaml"]

# 在这里声明具名卷，Docker 会自动为你创建和管理它们
volumes:
  go-pkg-mod:
  go-build-cache:

```

```bash
docker-compose up -d
docker-compose down
```

# 2025-10-27 使用非宿主机的 Go

```bash
docker pull golang:1.24.6

go build cmd/main.go -o lora-train-platform-server

改成下面这样：

docker run --rm \
  -v "$(pwd)":/app \
  -w /app \
  -e GOPROXY=https://goproxy.cn,direct \
  golang:1.24.6 \
  go build -o lora-train-platform-server cmd/main.go

```

- `-v "$(pwd)":/app`
	- 这是整个命令的魔法核心！`-v` 是 `--volume` 的缩写，用于将宿主机的文件或目录挂载到容器内部。
	- `"$(pwd)"`：在 Linux 和 macOS 中，这会自动替换为你的当前工作目录的绝对路径。如果你在 Windows 的 PowerShell 中，`"$(pwd)"` 也可以工作；如果是在 CMD 中，则需要使用 `"%cd%"`。
	- `:/app`：这是将宿主机目录挂载到容器内的 `/app` 目录。
	- 效果：这行命令相当于在容器里创建了一个通往你宿主机项目文件夹的 " 传送门 "。容器内的 Go 编译器就能读到你的 `cmd/main.go` 以及其他所有源代码文件了。
- `-w /app`
	- `-w` 是 `--workdir` 的缩写，它指定了容器内命令执行的工作目录。
	- 因为我们已经将项目挂载到了 `/app`，所以我们将工作目录也设置在这里。这样，`go build` 命令后面的相对路径 `cmd/main.go` 才能被正确找到。

# 2025-10-27 Go Proxy

ENV GOPROXY=<https://goproxy.cn>,direct

这个变量允许你指定一个或多个备用的下载源，Go 会按顺序尝试它们。

ENV GOPRIVATE="git.hoxigames.xyz"

这个变量是用来告诉 Go 哪些是你的私有模块，这些模块不应该被公共工具处理。

- 问题所在： Go 的设计非常注重安全和可验证性。当它下载一个公共模块时，会做两件事：
	1. 从 Go 代理（`GOPROXY`）获取代码。
	2. 从 Go 校验和数据库（`GOSUMDB`，一个公共服务器）获取一个加密哈希值，来验证代码没有被篡改。
	这对公共模块来说非常棒，但对私有模块来说就是个灾难！你公司的私有代码（比如在 `git.hoxigames.xyz` 上的）既不在公共代理上，也不在公共校验和数据库里。如果 Go 尝试去这些地方查找，就会失败报错。更糟糕的是，这会把你私有仓库的路径泄露给一个公共服务器。
- `GOPRIVATE` 的作用： 这个变量告诉 Go：" 嘿，任何路径以 `git.hoxigames.xyz` 开头的模块都是私有的，请用特殊方式处理它。"
- 当一个模块的路径匹配 `GOPRIVATE` 中的模式时，Go 会：
1. 绕过 `GOPROXY`：它会完全忽略 `goproxy.cn` 等代理。它会直接使用 Git 从 `git.hoxigames.xyz` 克隆代码。（这意味着你的构建环境必须配置好能访问这个私有仓库的 Git 凭证/SSH 密钥）。
2. 绕过 `GOSUMDB`：它不会尝试用公共校验和数据库去验证这个模块。

简单来说：`GOPRIVATE` 为你公司的内部代码创建了一个 " 安全和隐私的例外 "，确保 Go 不会尝试去公共互联网上查找它们。

# 2025-10-23 Golang 日志库

一个现代日志库通常由这几个核心部分组成，它们像一条流水线一样协同工作：

1. Logger (记录器): 这是你代码中直接调用的对象，比如 `logger.Info("用户登录成功")`。
2. Level (级别控制器): Logger 接收到日志后，首先检查这条日志的级别（如 `INFO`）是否高于或等于当前设定的最低级别。如果低于，就直接丢弃，节省性能。
3. Formatter (格式化器): 如果日志级别通过了检查，格式化器就会介入，把它变成预设的格式，比如纯文本或 JSON。
4. Output (输出器): 最后，输出器将格式化好的字符串写入指定的目标，比如标准输出（终端）、文件、或者网络连接。

注意事项

1. 始终使用结构化日志：尽量使用 `logger.WithFields()` 或类似方法添加上下文信息。不要写 `logger.Errorf("用户 %d 登录失败", userID)`，而要写 `logger.WithField("user_id", userID).Error("登录失败")`。这样 `user_id` 就是一个可供查询的字段。
2. 上下文信息是关键 (Context is King)：对于一个 Web 请求，把请求 ID (Request ID)、用户 ID 等信息注入到日志上下文中，这样你就可以串联起这个请求处理过程中的所有日志。
3. 不要记录敏感信息：绝对不要在日志中记录密码、身份证号、API Secret Key 等敏感数据。注意进行脱敏处理。
4. 日志级别要恰当
5. 在 `main` 函数或初始化时配置一次 Logger：通常我们会创建一个全局的或者通过依赖注入传递的 Logger 实例，而不是在每个函数里都创建一个新的。

日志库

- `Zap` 功能更全面，`Zerolog` 更极致和简洁。
- 相比于旧的 `log` 包（像是一个只会把书随便堆在架子上的管理员），`slog` 会给每一条信息都贴上清晰的标签（键值对），方便你日后快速查找和分析。
- `slog` 解决了这个问题：现在，库作者只需要面向 `slog` 的标准接口进行日志记录。而应用开发者可以在 `main` 函数里决定使用哪个 `Handler`（可以是 `slog` 自带的，也可以是 `zap` 或 `zerolog` 的 `slog` 适配器），从而统一整个应用的日志输出行为和格式。

# 2025-10-22 依赖注入

我明明把依赖传进去了，但这个依赖本身是个全局变量，这还算 DI 吗？" 答案是：你已经走在了正确的道路上，但离完美的依赖注入只差 " 最后一公里 "。你的代码部分实现了 DI 的思想，但可以做得更彻底、更优雅。

依赖应该像水流一样，从最高层（程序的入口，`main` 或 `Init`）" 注入 " 到最需要它的地方，而不是在中间某个环节突然从一个全局的 " 源头 " 冒出来。

我们把 `machineManager` 这个依赖从一个 " 全局静态资源 " 变成了一个在程序启动时被创建、并顺着对象关系图 " 流淌 " 下去的 " 动态实例 "。这样整个系统的耦合度更低，也更健壮和易于维护。

# 2025-10-22 Websocket

1. websocket 的交互必须相应吗? 如果不响应会出现什么问题？
	1. 对于业务数据消息，不是必须响应。但对于底层的 " 心跳 " 消息，则必须响应。
	2. HTTP 好比寄信： 你（客户端）寄出一封信（Request），然后必须等待邮局给你送回一封回信（Response）。一问一答，关系明确
	3. WebSocket 好比打电话： 双方一旦接通电话（建立连接），任何一方都可以随时说话，另一方可以听，也可以不回复，或者过一会儿再说别的话题。
	4. 总结： 对于业务数据，是否响应取决于你的应用需求。不响应不会导致 WebSocket 连接本身出问题。
2. websocket 是异步的吗？
	1. 绝对是！ 这是 WebSocket 的核心特性之一。
	2. 发送是异步的： 你调用 `socket.send(data)`，数据被交给浏览器/操作系统的网络堆栈去发送，你的代码可以立即继续执行下一行，而不用等待数据真正发送完毕。
	3. 接收是事件驱动的（也是异步的）： 你不需要写一个循环去不停地问 " 有新消息吗？"。你只需要注册一个 `onmessage` 事件监听器。当有新消息从服务器传来时，环境（浏览器/Node.js）会自动调用你提供的这个函数。
	4. 这使得 WebSocket 非常适合需要高并发和实时响应的场景，因为它不会阻塞用户界面或服务器主循环。
3. 如果不响应可以一直发送吗？
	1. 理论上可以，但实际上有限制。
	2. WebSocket 是建立在 TCP 之上的。TCP 有一个非常重要的机制叫做 " 流量控制 "（Flow Control）。当接收方的缓冲区快满时，它会通过 TCP 协议告诉发送方：" 慢点发，我来不及处理了！"
	3. 结论： 你可以在不收到对方响应的情况下持续发送消息，但这并非无节制。整个链路的发送速率受限于接收方的处理能力和网络状况，这由底层的 TCP 协议自动调节。
4. 那我怎么知道是回复的哪条呢？例如多个 ping，多个 pong 如何对应呢
	1. 在应用层实现自己的 " 心跳 " 机制。
	2. 业务消息匹配：由 你的应用程序 负责，通常通过在消息体中加入唯一 ID (Correlation ID / Request ID) 来实现。
5. websocket 也有协议层的 ping/pong

| 心跳类型      | **协议层 Ping/Pong**            | **应用层 自定义心跳**           |
| --------- | ---------------------------- | ----------------------- |
| **负责人**   | WebSocket 协议、浏览器、服务器框架       | **你 (应用程序员)**           |
| **工作内容**  | 检查物理连接是否通畅 (" 网线还插着吗？")       | 检查业务逻辑是否正常 (" 你还在玩游戏吗？") |
| **携带信息**  | 无或非常少 (用于匹配)                 | **丰富** (服务器负载、用户状态等)    |
| **对你的帮助** | 提供可靠的 `onopen`, `onclose` 事件 | **实现具体的业务功能**           |

# 2025-09-16 URL 后面的斜杠

URL (通常我们说的 " 网址 ") 末尾的斜杠（Trailing Slash），在最原始和经典的 Web 模型中，是用来区分一个 " 目录（Directory）" 和一个 " 文件（File）" 的标志。

- `https://example.com/about/` 👈 末尾有斜杠，暗示这是一个目录。
- `https://example.com/about` 👈 末尾没有斜杠，暗示这是一个文件。

虽然现代 Web 框架在很大程度上模糊了这种区别，但这个底层逻辑依然是理解所有相关问题的关键。

在搜索引擎（如 Google）眼中，`example.com/about/` 和 `example.com/about` 是两个**完全不同**的 URL。如果它们返回相同的内容，就会被判定为 " 重复内容 "（Duplicate Content），这会分散你的页面权重，对排名非常不利。

## 实现原理

让我们来看看，当一个请求到达 Web 服务器（比如 Nginx 或 Apache）时，经典的 " 幕后故事 " 是怎样的。

工作流程：服务器如何处理斜杠

1. 浏览器请求：你向服务器请求 `https://example.com/users` (没有斜杠)。
2. 服务器检查：服务器首先会在网站根目录下查找一个名为 `users` 的文件。
3. 判断与行动：
	- 情况 A：如果 `users` 文件存在
		- 服务器直接返回该文件的内容。
	- 情况 B：如果 `users` 文件不存在，但存在一个 `users` 目录
		- 服务器会认为：" 哦，你可能想访问的是这个目录，但你的地址写得不标准。"
		- 它会向浏览器返回一个 301 永久重定向响应，告诉浏览器：" 请你以后访问 `https://example.com/users/` (带斜杠) 这个地址。"
		- 浏览器收到后，会立即发起一个到新地址 `https://example.com/users/` 的新请求。
	- 情况 C：如果 `users` 目录被请求 (带斜杠)
		- 服务器会查找该目录下的默认文件（例如 `index.html`, `index.php` 等），并返回其内容。

## 注意事项

1. 根域名是个例外：对于 `https://example.com`，浏览器会自动处理成 `https://example.com/`。你不需要关心根域名的斜杠，它总是被视为一个 " 目录 "。
2. 指向文件的 URL 不加斜杠：当 URL 明确指向一个文件时，比如 `https://example.com/assets/style.css` 或 `https://example.com/user/avatar.jpg`，永远不要在末尾加斜杠。加上斜杠在语义上是错误的，并且很可能导致 404。
3. 在设计 RESTful API 时，虽然斜杠的 " 目录 " 含义被淡化，但一致性仍然重要。比如，`GET /api/users` 获取用户列表，`GET /api/users/123` 获取单个用户。如果你允许 `/api/users/` 也能访问列表，就会造成混乱。通常的 REST 惯例是**不**在资源集合（`/users`）后加斜杠。
4. 双斜杠 `//` 的问题: 如果你不小心在 URL 中写了 `https://example.com/path//to/resource`，大多数现代浏览器和服务器会将其 " 折叠 " 成一个斜杠，即 `.../path/to/resource`。但依赖它是个坏习惯，因为它在某些旧系统或配置下可能导致不可预料的行为。

## 相对路径

这是最常见、最直接的 bug。假设你的页面 URL 是 `https://example.com/user/profile` (无斜杠)。  
页面里的一个相对路径链接 `<a href="settings">...</a>` 会被浏览器解析为：`https://example.com/user/settings` (替换了最后一部分)。

但如果你的页面 URL 是 `https://example.com/user/profile/` (有斜杠)。  
同样的链接 `<a href="settings">...</a>` 会被解析为：`https://example.com/user/profile/settings` (在当前路径下追加)。  
看到区别了吗？一个斜杠，URL 解析天差地别，这常常是导致 CSS/JS 加载失败的元凶。

# 2025-09-16 网盘离线下载

" 离线网盘 " 并不是说这个网盘本身可以脱离网络使用。离线网盘 = 普通网盘 + 离线下载功能。

离线下载本质是下载到我的网盘上，其实我还是需要从网盘上下载到我的本地。

想象一个场景：你想在网上买一个很远地方的、而且运送起来很麻烦的宝贝（比如一个大冰箱）。

- 传统下载方式： 你自己开车（用你家的网速），花很长时间，经历堵车、迷路（网络不稳定、速度慢），好不容易才把冰箱从那个遥远的仓库拉回家里。这个过程中，你和你的车必须全程参与。
- 离线下载方式： 你只需要把那个宝贝的地址（下载链接）告诉一个 " 超级代购管家 "（网盘服务器）。这个管家拥有火箭般的速度和专用通道（超高速带宽），他会瞬间帮你把冰箱取回来，先放在他自己的仓库里（你的网盘空间）。然后，你随时可以开着你的小车，去管家那个又近又方便的仓库，轻松地把冰箱取回家（从网盘下载到你的电脑）。

" 离线下载 " 的过程就是这样：

1. 你下达指令： 你找到一个文件的下载链接（比如 HTTP、FTP 链接，或者更常见的 BT 种子、磁力链接）。
2. " 管家 " 出动： 你把这个链接粘贴到网盘的 " 离线下载 " 任务栏里。网盘的服务器（那位 " 超级管家 "）就会接管这个任务。
3. 服务器代你下载： 网盘服务器利用它自己极其强大、稳定、高速的带宽，去从原始地址下载这个文件。在这个过程中，你的电脑可以关机，可以断网，完全不用管。这就是 " 离线 " 的含义——对于你的个人设备来说，你是 " 离线 " 的。
4. 存入你的 " 仓库 "： 文件下载完成后，会自动保存在你的网盘空间里。
5. 你再去取回： 现在，文件已经稳稳地在网盘上了。你可以随时随地，使用你自己的网络，从网盘服务器把它高速下载到你的电脑、手机或平板上。这个速度通常会比你直接从原始地址下载快得多、稳定得多。

## 为什么可以做到离线下载？

这背后的原理其实很简单，主要基于以下几点：

1. " 代下载 " 模式： 核心就是 " 服务器替你下载 "。你只是一个发号施令的人，真正干活（下载）的是网盘背后的庞大服务器集群。它们 7x24 小时在线，拥有我们家庭网络无法比拟的带宽和稳定性。
2. 强大的基础设施： 像百度网盘、115 网盘这些服务商，都投资建设了巨大的数据中心，里面有成千上万台服务器和超高速度的互联网接口。让它们去下载一个几十 GB 的文件，可能只是几分钟甚至几十秒的事情。
3. " 秒传 " 技术（一个神奇的 " 作弊 " 技巧）： 这是让离线下载体验变得 " 魔幻 " 的关键。
	- 原理： 当你提交一个下载链接时，网盘服务器会先计算这个文件的 " 指纹 "（也就是哈希值，一个独一无二的识别码）。
	- 检查库存： 然后，它会检查自己的巨大资源库，看看有没有其他用户已经下载过这个一模一样的文件（拥有相同 " 指纹 " 的文件）。
	- 瞬间完成：
		- 如果服务器上已经有了这个文件，它根本不需要重新下载！它只需要在你的网盘空间里创建一个 " 快捷方式 " 或 " 指针 "，指向那个已经存在的文件。对你来说，这个过程是瞬间完成的，也就是我们常说的 " 秒传 "。
		- 如果服务器上没有，它才会启动下载程序，去老老实实地把文件下载回来。

# 2025-08-21 Idfa 和 Idfv

- **IDFA (Identifier for Advertisers / 广告标识符)**：这是苹果分配给每台设备的、一个**跨 App** 的、可重置的匿名设备标识符。它的唯一目的就是用于广告追踪，比如衡量广告效果和投放个性化广告。
- **IDFV (Identifier for Vendors / 开发商标识符)**：这也是苹果分配的设备标识符，但它只在**同一个开发商（Vendor）旗下**的所有 App 之间共享。它主要用于开发商在自己的 " 小生态 " 内分析用户行为。

区别：

- **IDFA** 就像是你在进入购物中心时，工作人员发给你的一张**匿名的、临时的访客胸牌（比如 " 访客 89757 号 "）**。商场里所有的店铺（不同的 App）都能看到这个胸牌号码，用来识别你。但你可以随时去服务台要求换一个新的号码（重置），或者干脆拒绝佩戴（禁止追踪），这样就没人能认出你了。
- **IDFV** 就像是你办了一张特定连锁超市（比如 " 沃尔玛 "）的**会员卡**。只有沃尔玛旗下的所有分店（同一个开发商的 App）能识别你的会员卡号，他们可以用它来记录你的购物习惯、给你积分。其他超市（其他开发商的 App）是不知道也不认这个卡号的。只要你手机上还留着任何一个沃尔玛的 App，这个会员卡号就不会变。

策略

- 自 iOS 14.5 以后，苹果推出了 AppTrackingTransparency (ATT) 框架。你**必须**先弹窗请求用户授权，用户同意后才能获取到有效的 IDFA。不理解这个机制，你的应用不仅无法获得 IDFA，甚至可能被 App Store 拒绝。
	- 优雅地处理拒绝: 要为获取不到 IDFA（返回全零字符串）的情况做好准备。你的广告逻辑或分析逻辑不能因此而崩溃。
- 获取 IDFV 则简单得多，因为它不涉及用户隐私追踪，无需授权。
	- IDFV 仅限于你自己的 App 之间使用。严禁将其分享给其他公司用于广告追踪，这是违反苹果政策的。

提问问题

- " 既然 IDFA 要授权这么麻烦，那我用 IDFV 来做广告追踪行不行？"
	- 绝对不行！这是对概念的根本性误解。广告平台（比如 Meta、Google）无法识别你的 IDFV。IDFV 在你的 App A 里是一个值，在别人家的 App B 里是另一个值，无法建立追踪链接。这种做法不仅无效，还违反苹果开发者协议。
- idfa 授权后，不同的 app，看到的是同一个吗
	- 在用户授权之后，同一台设备上不同的 App 获取到的 IDFA 是完全相同的。

# 2025-08-12 评论系统 Waline

<https://waline.js.org/> 一定用国际版，减少好多事。

如果遇到跨域问题，大概是自己的 serverURL 没写对

 serverURL: <https://waline-liuvv.vercel.app>

管理系统： <https://waline-liuvv.vercel.app/ui>

# 2025-07-20 Ishot 贴图和多窗口截图配合

贴图：截图后点击贴图按钮。

多窗口：按下截图按钮，再按 shift，点多个窗口，然后松开快捷键。

# 2025-07-19 127.0.0.1 和 Localhost 的区别

- 127.0.0.1：是一个具体的 IP 地址
- localhost：是一个主机名（hostname），需要被解析成 IP 地址: `localhost → DNS 解析/hosts 文件 → 127.0.0.1

| 特性      | 127.0.0.1                                     | localhost                                                           |
| ------- | --------------------------------------------- | ------------------------------------------------------------------- |
| 类型      | IP 地址 (IP Address)                            | 主机名 (Hostname)                                                      |
| 所属层级    | 网络层 (Network Layer)                           | 应用层 (Application Layer)                                             |
| 工作方式    | 直接使用，无需解析。                                    | 需要通过系统解析成一个 IP 地址后才能使用。                                             |
| 可变性     | 标准固定。它是一个由 IETF (互联网工程任务组) 标准化的特殊用途地址，永远指向本机。 | 理论上可配置。虽然它默认指向 `127.0.0.1`，但你可以通过修改 `hosts` 文件让它指向其他地址（但强烈不建议这样做！）。 |
| IPV4/V6 | 仅支持 IPv4                                      | IPv4: `127.0.0.1` IPv6: `::1 `                                      |

## Mysql 连接的区别

```bash
// 使用 localhost - 默认使用 Unix socket 连接，Socket 文件通信绕过了整个网络协议栈，没有 TCP 握手、数据包封装/解封装等开销，延迟更低。	
$conn = new mysqli("localhost", "user", "pass");
// 使用 127.0.0.1 - 强制使用 TCP/IP 连接
$conn = new mysqli("127.0.0.1", "user", "pass");


// 即使是 localhost，只要指定了端口，就会强制使用 TCP/IP
$conn = new mysqli("localhost:3306", "user", "pass");
// 这行代码和上面那行的效果是完全一样的
$conn = new mysqli("127.0.0.1:3306", "user", "pass");
```

- 场景一：使用 `localhost` 失败，但用 `127.0.0.1` 成功。
	- 原因：很可能是 MySQL 服务器没有配置使用 Socket 文件，或者 Socket 文件的路径不正确/权限错误。但服务器配置了监听 TCP 端口 `3306`。
- 场景二：使用 `127.0.0.1` 失败，但用 `localhost` 成功。
	- 原因：这通常是出于安全考虑的配置。管理员可能在 MySQL 配置文件 (`my.cnf`) 中加入了 `skip-networking` 指令，这会完全禁用 MySQL 的 TCP/IP 网络监听，只允许通过 Socket 文件进行本地连接。这样可以防止任何来自网络的连接尝试。
- 场景三：在 Windows 系统上
	- 在 Windows 上，没有 Unix Domain Socket。因此，`mysqli` 会将 `localhost` 解析为 `127.0.0.1`，最终两者都会使用 TCP/IP 进行连接。所以在 Windows 环境下，这两行代码的行为和性能几乎没有区别。

# 2025-07-19 设置服务器语言环境

设置系统的语言环境（locale）变量，确保程序能正确处理各种语言的字符（中文、日文、特殊符号等)

- LANG: 设置默认的语言环境
- LC_ALL: 覆盖所有其他的 LC_* 设置，优先级最高

```bash
export LANG=C.UTF-8 
export LC_ALL=C.UTF-8
```

# 2025-07-19 Watch 命令

`watch -n 1` 是一个 Linux/Unix 命令，用于每隔 1 秒重复执行一次后面的命令，并实时显示输出结果。

```bash
# 每隔1秒执行一次
watch -n 1 date
# 每隔5秒执行一次
watch -n 5 "ps aux | grep nginx"
# 支持小数，每0.5秒执行一次
watch -n 0.5 "netstat -an | grep :80"


# 高亮显示每次输出的差异
watch -d free -m
# 持续高亮所有变化过的内容
watch -d=cumulative uptime
```

# 2025-07-15 AWS ElastiCache Serverless 模式

ElastiCache Serverless 是一种无服务器（serverless）部署模式。您不需要手动指定节点数量、分片（shards）或配置高可用性；AWS 会自动处理自动缩放、故障转移和维护。用户只需提供预期的读/写吞吐量（例如，每秒请求数），系统会动态调整后端资源。

Serverless 模式隐式启用 Redis 集群模式（Cluster Mode Enabled）。数据会被自动分布到多个内部分片（shards）上，以实现水平扩展和高可用性。

如果您的配置确实是 Serverless，这意味着您的 Redis 是一个隐式集群，但不是您可以手动控制的 " 多独立 Master" 架构。

## Go 使用库的推荐

Serverless 提供单一端点，但内部是集群化的。`bsm/redislock` 可以无缝工作，因为 `go-redis/v9` 支持通过单一端点连接 Redis Cluster（它会自动处理 `MOVED` 重定向）。您无需担心内部分片。

 Redlock 算法需要连接多个独立的 Redis Master 节点。在 Serverless 中，这些节点是内部管理的，您无法获取它们的独立端点（只有单一端点）。因此，无法实现标准的 Redlock。高可用性由 AWS 自动处理，无需手动 Redlock。所以不用使用红锁的库。

真正的 redis cluster，也可以使用 `bsm/redislock`

# 2025-07-09 Gin Context 和 Context 区别

## Context 区别

- `*gin.Context` 是 Gin 框架自己定义的一个结构体。它的主要职责是处理和封装单次 HTTP 请求和响应的所有信息。你可以把它看作一个 "Web 工具箱 "，它提供了大量便捷的方法。**
- `context.Context` 是 Go 语言标准库 `context` 包中定义的一个接口。它的核心目标是在不同 API 边界和 goroutine 之间传递请求的截止时间（deadline）、取消信号（cancellation signal）以及其他与请求相关的值。
- `context.Background()` 是一个特殊的、空的 `context.Context`。它通常用作所有 context 链的根节点，因为它永远不会被取消，没有值，也没有截止日期。它适用于那些不与任何特定请求关联的场景，比如：在 `main` 函数中启动一个长期运行的后台任务。一个程序的初始化过程。

## 业务逻辑应该传递哪个

`*gin.Context` 确实实现了 `context.Context` 接口。从技术上讲，任何接受 `context.Context` 类型参数的函数，你都可以直接把 `*gin.Context` 的实例 `c` 传递给它。那么，既然可以，为什么几乎所有的最佳实践和教程都推荐使用 `c.Request.Context()` 呢？

- `*gin.Context` 的职责是 Web 层。它是一个 " 胖 " 对象，包含了处理 HTTP 请求和响应的所有工具：参数解析、JSON 渲染、设置 Cookie、中间件控制等等。
- 你的业务逻辑层 (`fetchUserData` 函数) 或数据访问层 (DAO) 的职责是处理业务，它根本不应该，也不需要知道什么是 HTTP，什么是 JSON 响应，什么是 Gin 框架。

# 2025-07-08 Aws 卷的 Iops 和吞吐量

	 aws 卷的 iops （3000） 和 Throughput (125 MiB/s)

- IOPS
	- IOPS (Input/Output Operations Per Second) - 每秒输入/输出操作次数，一秒钟内可以处理的读写操作的总次数。
	- IOPS 就像是每秒钟能通过收费站的货车数量。无论每辆车装的是一个小包裹还是一整车家具，它都只算作 " 一辆车 "。
	- IOPS 决定了你的硬盘 " 反应有多快 "，能否同时处理大量并发请求。
- Throughput 吞吐量 (兆字节/秒)
	- 衡量存储设备在一秒钟内可以成功传输的数据总量，通常以 `MiB/s` 或 `MB/s` 为单位。
	- Throughput 就像是高速公路的总宽度。它决定了这条路在同一时间内总共能承载多大的车流量（数据流）。

# 2025-07-07 Mysql 字符集和排序规则

```sql
CREATE DATABASE mydb CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
```

- utf8mb4: 字符集
	- 支持完整的 Unicode 字符集（包括 emoji 😊）
	- 每个字符最多使用 4 个字节
	- MySQL 8.0+ 的默认字符集
	- 兼容性最好
- 0900: Unicode 9.0.0 标准
- ai: Accent Insensitive（重音不敏感）
- ci: Case Insensitive（大小写不敏感）

# 2025-07-06 FP16 和 BF16 区别

FP16 和 BF16 是两种不同的 16 位浮点数格式，主要区别在于位数分配。

- FP16 的范围小得多，容易出现上溢和下溢，BF16 的范围与 FP32 相同（因为指数位相同）
- FP16 精度更高（10 位尾数 vs 7 位尾数）

使用场景：

- 模型训练中，梯度（Gradients）等中间值不容易因变得过大或过小而溢出，BF16 已成为主流选择。
- 模型推理时，权重已经固定，数值范围相对稳定。此时，FP16 更高的精度有助于得到更准确的最终结果。

# 2025-06-25 Pkill 使用教程

## Kill 和 Pkill 的区别

kill 必须先找到进程 ID

```bash
ps aux | grep firefox
kill 1234           # 使用具体的PID
```

pkill 直接使用进程名

```bash
pkill fire # 无需知道 PID, 危险：可能匹配 firefox, firewall 等

pkill -x firefox    # 精确匹配，更安全的做法

pkill -f "python script.py" # 匹配完整的命令行
```

## Pkill -f 匹配完整的命令行

`pkill -f` 的作用是**匹配完整的命令行**，而不带 `-f` 只匹配**进程名称**。这是一个非常重要的区别：

```bash
user  1234  python /home/user/scripts/web_server.py --port 8080
user  5678  python /home/user/scripts/data_processor.py --input data.csv
user  9012  python /home/user/scripts/backup.py


# 只匹配进程名 "python"
pkill python
# 结果：会终止所有 python 进程（1234, 5678, 9012）

# 尝试匹配脚本名（失败）
pkill web_server.py
# 结果：不会匹配任何进程，因为进程名是 "python"，不是 "web_server.py"


# 匹配完整命令行
pkill -f web_server.py
# 结果：只终止 PID 1234 的进程

pkill -f "data_processor.py --input"
# 结果：只终止 PID 5678 的进程

pkill -f "/home/user/scripts/"
# 结果：终止所有在该目录下的脚本（1234, 5678, 9012）
```

# 2025-06-24 Where a > ? and B = ? Order by C

mysql 的一个查询语句，where a > ? and b = ? order by c ，怎么创建索引会比较好

- 最理想的索引是 `INDEX(b, a, c)。
- order by 仍然需要进行 filesort，因为无法保证 c 列是全局有序的。但是有可能成为覆盖索引（select 3 个字段）无需回表。

1. **`WHERE b = ?`**：MySQL 首先使用索引的第一部分 `b`。因为是等值查询，它可以非常快地将搜索范围缩小到 `b` 等于特定值的那些行。
2. **`WHERE a > ?`**：在已经筛选出的 `b` 值相同的这个小范围内，MySQL 接着使用索引的第二部分 `a` 来进行范围查找，过滤掉不满足 `a > ?` 的行。
3. **`ORDER BY c`**：由于索引是按照 `(b, a, c)` 的顺序创建的，当 `b` 和 `a` 的值确定后（或者在一个小的范围扫描内），`c` 字段在索引中**自然就是有序的**。因此，MySQL 可以直接按照索引顺序读取数据，**避免了昂贵的文件排序（filesort）操作**。

# 2025-06-14 Http Server 的 Request.Context 超时

## http.Server 超时

1. **`http.Server.ReadTimeout`**: 这是 Go 标准库 `http.Server` 在**传输层**的超时。它覆盖了从接受连接开始，到读取完所有请求头和请求体（Request Body）的时间。如果客户端在这个时间内没有发送完数据，`http.Server` 会直接关闭连接，通常会导致客户端收到一个 `503 Service Unavailable` 响应。
2. **`http.Server.WriteTimeout`**: 这也是传输层的超时。它覆盖了从 handler 执行完毕，开始写入响应（Response）到响应完全写完的时间。

- golang 启动一个 http.Server， http.Request.Context() 是怎么控制的？

```bash
func main() {
    server := &http.Server{
        Addr:         ":8080",
        Handler:      http.HandlerFunc(handler),
        ReadTimeout:  10 * time.Second,
        WriteTimeout: 10 * time.Second,
    }
    
    log.Fatal(server.ListenAndServe())
}

```

## Go-zero 是怎么控制的？

```go
// rest.conf 配置
RestConf:
  Host: 0.0.0.0
  Port: 8888
  Timeout: 30000  # 30秒超时
  
// go-zero 自动应用超时控制，简化版
func (s *Server) Start() {
	handleError(s.ngin.start(s.router))
}

func newEngine(c RestConf) *engine {
	svr := &engine{
		conf:    c,
		timeout: time.Duration(c.Timeout) * time.Millisecond,
	}
	return svr
}


func (ng *engine) start(router httpx.Router, opts ...StartOption) error {
	// make sure user defined options overwrite default options
	opts = append([]StartOption{ng.withTimeout()}, opts...)
	return internal.StartHttps(ng.conf.Host, ng.conf.Port, ng.conf.CertFile,
		ng.conf.KeyFile, router, opts...)
}

func (ng *engine) withTimeout() internal.StartOption {
	return func(svr *http.Server) {
		timeout := ng.timeout
		if timeout > 0 {
			// 设置为全局超时的 80%，考虑一个恶意或有 bug 的客户端。它发送了一个 Content-Length: 1000000 的请求头，但实际上只发送了 100 字节的数据，然后就一直保持连接不发送剩余数据。当 ReadTimeout 和 go-zero 的应用层超时同时到达时，传输层的 ReadTimeout 可能会先生效。http.Server 会直接中断连接，并返回一个 503 错误。503 通常被认为是服务不可用，如果上游有类似 Istio 的服务网格或 Nginx 等代理，它们可能会认为这个服务实例已经宕机，从而触发熔断机制，在一段时间内不再将流量转发到这个实例，造成服务雪崩的风险。 
			//将 ReadTimeout 设置为全局超时的 80%。这样，在上述场景中，ReadTimeout 会比 go-zero 的应用层超时先到期。但是，因为 go-zero 的超时控制更精确，它会在全局超时（100%）到达时由应用层中间件捕获到超时。这个中间件会返回一个更友好的、可控的错误（例如 408 Request Timeout 或自定义的业务错误码），而不是由底层 http.Server 返回粗暴的 503。这样就避免了触发熔断，保护了服务。本质上是让应用层（Go-Zero）有机会比传输层（http.Server）先处理超时。
			svr.ReadTimeout = 4 * timeout / 5
			
			
			// 例如，timeout 是 5 秒，业务逻辑执行了 4.9 秒。如果 WriteTimeout == timeout: 业务逻辑在 4.9 秒时处理完成，go-zero 开始将响应数据写回给客户端。但是，留给写入操作的时间只剩下 0.1 秒。如果响应数据比较大，或者客户端网络状况不佳，0.1 秒内很可能无法完成写入。这时 WriteTimeout 就会触发，连接被中断，客户端只收到了一个不完整的响应。
			// 将 WriteTimeout 设置为全局超时的 110%（也就是 timeout + 10% 的缓冲时间）。在上述场景中，即使业务逻辑用满了全部的 5 秒，服务器仍然有额外的 0.5 秒（5 * 10%）时间来完成响应的写入操作。这大大增加了响应能够被完整发送到客户端的概率，提高了系统的可靠性。
			svr.WriteTimeout = 11 * timeout / 10
		}
	}
}


func StartHttp(host string, port int, handler http.Handler, opts ...StartOption) error {
	return start(host, port, handler, func(svr *http.Server) error {
		return svr.ListenAndServe()
	}, opts...)
}

func start(host string, port int, handler http.Handler, run func(svr *http.Server) error,
	opts ...StartOption) (err error) {
	server := &http.Server{
		Addr:    fmt.Sprintf("%s:%d", host, port),
		Handler: handler,
	}
	for _, opt := range opts {
		opt(server)
	}
}
```

# 20250613 Mysql Text 默认值问题

MySQL 的 text 可以 not null 有默认值吗？ MySQL 8.0.13 及更高版本：可以。

```bash
-- MySQL 8.0.13+ 可以正常执行
CREATE TABLE test (
    content TEXT NOT NULL DEFAULT ('hello')
);
```

之前的版本，TEXT 类型的字段可以设置为 NOT NULL，但不能直接设置默认值。

MySQL 的 TEXT 类型属于大对象（LOB），存储在表的行外（即存储为指针）。由于其设计限制，MySQL 不允许直接为 TEXT 类型字段设置默认值，除非使用特定的方法绕过这个限制。

# 20250611 AWS 创建数据库

创建数据库：abc-analyze-db

- vpc 选对
- vpc security group 选对

查看密码：Secrets Manager

创建新用户和密码

```bash
docker exec -it mysql mysql -habc-analyze-db.xxxx.us-west-2.rds.amazonaws.com -uadmin -p'I9s87' -Dabc

# 添加新用户
CREATE USER 'abc_rw'@'%' IDENTIFIED BY 'mima';
GRANT SELECT, INSERT, UPDATE, DELETE ON picplus.* TO 'abc_rw'@'%';
GRANT CREATE, DROP, ALTER, INDEX ON picplus.* TO 'abc_rw'@'%';
FLUSH PRIVILEGES;


# 查看
SELECT User, Host FROM mysql.user WHERE User = 'abc_rw';
SHOW GRANTS FOR 'abc_rw'@'%';


# 最后
abc-analyze-db.xxxx.us-west-2.rds.amazonaws.com
abc_rw
mima
```

# 20250610 AWS 创建数据库从库

数据库 -> Action-> Create read replica （默认选项）

注意账号和密码和主库都一样。

# 20250607 Deeplx 免费翻译服务

```bash
# deeplx 配合 bob，我部署后无法使用，出现 503
项目： https://github.com/OwO-Network/DeepLX
部署：  docker run -itd -p 1188:1188 ghcr.io/owo-network/deeplx:latest
bob插件：https://github.com/missuo/bob-plugin-deeplx


# linuxdo 站长提供的免费 deeplx，可以用在 bob 和 沉浸式翻译里，这个最好用
https://connect.linux.do/
https://api.deeplx.org/你的key/translate
```

# 20250606 清理 Git 分支

```bash
# 清理远程删除的分支
git fetch --prune --prune-tags


# 删除所有远程已删除的本地分支
git branch -vv | grep ': gone]' | awk '{print $1}' | xargs git branch -d
```

# 20250604 Socket 和 Websocket

| 特性        | Socket       | WebSocket    |
| --------- | ------------ | ------------ |
| **协议层级**  | 传输层（TCP/UDP） | 应用层（基于 HTTP） |
| **使用场景**  | 任何网络应用       | Web 应用       |
| **浏览器支持** | 不直接支持        | 原生支持         |
| **连接建立**  | 直接 TCP 连接    | HTTP 握手后升级   |
| **数据格式**  | 二进制/文本       | 帧格式（文本/二进制）  |
| **跨域**    | 无限制          | 受同源策略影响      |

## Socket

1. 三次握手建立 TCP 连接
2. 直接发送/接收数据
3. 四次挥手关闭连接

- 更灵活，可以实现各种协议
- 性能更高，开销更小
- 可以使用 UDP 实现低延迟通信
- 浏览器不能直接使用

## WebSocket

1. HTTP 请求（包含 Upgrade 头）
2. 服务器返回 101 状态码
3. 协议升级为 WebSocket
4. 双向通信

- 浏览器原生支持
- 与 HTTP 共用端口（80/443）， 可以穿透大多数防火墙
- 仅支持 TCP，不支持 UDP
- 有一定的协议开销

## 如何选择

选择 Socket ：不需要浏览器访问，需要 UDP 或自定义协议，追求极致性能，开发系统级应用。

选择 WebSocket ：需要浏览器实时通信，开发 Web 应用，需要跨平台兼容，希望简化开发流程。

两者可以配合使用，比如后端服务间用 Socket 通信，前端与后端用 WebSocket 通信。

# 20250527 Gmail 转发 到 Qq 邮箱

设置 -> 转发和 POP/IMAP -> 转发 -> 将收到的邮件的副本转发给 xxx@ (正在使用) 和在收件箱中保留 Gmail 的副本

# 20250516 数据库每天都要看压力

- 解决 top sql，降低 CPU 和 Sessions
- <https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.UsingDashboard.Opening.html>
- 在当前活动下，会话项目显示在过去五分钟内平均活跃会话中的数据库负载。条形图显示负载量。当条形图为空时，数据库实例处于空闲状态。随着负载的增加，条形图会以蓝色填充。当负载超过数据库实例类上的虚拟 CPU (vCPU) 数量时，条形图变为红色，表示可能出现瓶颈。
- 超过 max vCPU 的线就会红
- ![400](/img/user/Publish/%E6%8A%80%E6%9C%AF%E5%8D%A1%E7%89%87%E7%AC%94%E8%AE%B0/11519596_b284cd0b-069e-4271-8ff4-4ce2aa13ad52.png)
- ![400](/img/user/Publish/%E6%8A%80%E6%9C%AF%E5%8D%A1%E7%89%87%E7%AC%94%E8%AE%B0/11519596_cd2e9067-74ef-446f-e147-cedaf2d85067.png)
